{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# TODO: \n",
    "- exclude lines with less than 5km\n",
    "- night and day (...person vs freight)\n",
    "- congestion of operatoin points\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "operating_points_df = pd.read_csv(data_dir + 'linie-mit-betriebspunkten.csv',\n",
    "                              delimiter=';')\n",
    "train_tracks_df = pd.read_csv(data_dir + 'zugzahlen.csv',\n",
    "                              delimiter=';')\n",
    "construction_df = pd.read_csv(data_dir + 'construction-site.csv',\n",
    "                              delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Congestion:\n",
    "    def __init__(self, passenger_value=0, freight_value=0):\n",
    "        self.passenger_value = passenger_value\n",
    "        self.freight_value = freight_value\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"passenger_value: {self.passenger_value} | freight_value: {self.freight_value}\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Congestion(self.passenger_value + other.passenger_value, self.freight_value + other.passenger_value)\n",
    "        \n",
    "    def increase_passenger_value(self, increment):\n",
    "        self.passenger_value += increment\n",
    "        \n",
    "    def increase_freight_value(self, increment):\n",
    "        self.freight_value += increment\n",
    "\n",
    "class Operating_point:\n",
    "    def __init__(self, id_index, id_word, gps):\n",
    "        self.id_index = id_index\n",
    "        self.id_word = id_word\n",
    "        self.gps = gps\n",
    "        self.connections_inbound = []\n",
    "        self.connections_outbound = []\n",
    "        self.congestion = Congestion()\n",
    "        self.lines = []\n",
    "        \n",
    "    def add_connection_outbound(self, connection):\n",
    "        self.connections_outbound.append(connection)\n",
    "            \n",
    "    def add_connection_inbound(self, connection):\n",
    "        self.connections_inbound.append(connection)\n",
    "        \n",
    "    def add_line(self, line_id):\n",
    "        self.lines.append(line_id)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.id_index:d} {self.id_word} {self.gps} \" + \\\n",
    "               f\"outbound: {self.connections_outbound} | inbound: {self.connections_inbound}\\n\" \\\n",
    "               f\"congestion: {self.congestion}\"\n",
    "    \n",
    "class Connection:\n",
    "    def __init__(self, from_op, to_op, trains, load, train_type):\n",
    "        self.from_op = from_op\n",
    "        self.to_op = to_op\n",
    "        self.trains = trains\n",
    "        self.load = load\n",
    "        self.train_type = train_type\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.from_op} {self.to_op} {self.trains} {self.load}\"\n",
    "\n",
    "class Connection_congestion:\n",
    "    def __init__(self, smaller_op, greater_op, congestion=None):\n",
    "        self.smaller_op = smaller_op\n",
    "        self.greater_op = greater_op\n",
    "        if congestion is not None:\n",
    "            self.congestion = congestion\n",
    "        else:\n",
    "            self.congestion = Congestion()\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"Connection_congetion {self.smaller_op} <-> {self.greater_op}: \" + str(self.congestion) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = dict()\n",
    "\n",
    "for index, row in operating_points_df.iterrows():\n",
    "    id_word = row['Abbreviation of the operating point']\n",
    "    \n",
    "    points.setdefault(id_word,\n",
    "                      Operating_point(index,\n",
    "                                      id_word,\n",
    "                                      (row['E'], row['N'])))\n",
    "    points[id_word].add_line(row['LINIE'])\n",
    "\n",
    "outside_ind = 9000\n",
    "\n",
    "def add_outside(op):\n",
    "    global outside_ind\n",
    "    if op.id_word not in points:\n",
    "        points.setdefault(op.id_word, op)\n",
    "        outside_ind += 1\n",
    "    \n",
    "for index, row in train_tracks_df.iterrows():\n",
    "    from_op = row['BP_Von_Abschnitt']\n",
    "    to_op = row['BP_Bis_Abschnitt']\n",
    "    if (from_op not in points.keys()): # connection enters Switzerland\n",
    "        add_outside(Operating_point(outside_ind, from_op, (0,0)))\n",
    "    if (to_op not in points.keys()): # connection leaves Switzerland\n",
    "        add_outside(Operating_point(outside_ind, to_op, (0,0)))\n",
    "    \n",
    "\n",
    "    new_connection = Connection(from_op, to_op,\n",
    "                                row['Anzahl_Zuege'], \n",
    "                                row['Gesamtbelastung_Bruttotonnen'],\n",
    "                                row['Geschaeftscode'])\n",
    "    points[from_op].add_connection_outbound(new_connection)\n",
    "    points[to_op].add_connection_inbound(new_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords = []\n",
    "y_coords = []\n",
    "ids = []\n",
    "incidence_list = {}\n",
    "for point in points.values():\n",
    "    ids.append(point.id_index)\n",
    "    x_coords.append(point.gps[0])\n",
    "    y_coords.append(point.gps[1])\n",
    "    incidence_list[point.id_index] = []\n",
    "    \n",
    "    for connection in point.connections_outbound:\n",
    "        incidence_list[point.id_index].append(points[connection.to_op].id_index)\n",
    "    \n",
    "vis_data = {'ID': ids,\n",
    "        'x': x_coords,\n",
    "        'y': y_coords,\n",
    "        'IL': incidence_list}  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "with open('vis_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(vis_data, handle)\n",
    "\n",
    "with open('vis_data.pickle', 'rb') as handle:\n",
    "    vis_data = pickle.load(handle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from viz import map\n",
    "\n",
    "map = map.Map(vis_data, \"test\")\n",
    "map.plotnodes()\n",
    "map.plotedges()\n",
    "#map.showmap()\n",
    "map.saveplot(\"test.html\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter constructions without 'Umsetztung' or with 'Umleitung'\n",
    "construction_df = construction_df[construction_df['Umsetzung / \\nIntervalltyp / Umleitung'].notnull()]\n",
    "construction_df = construction_df[construction_df['Umsetzung / \\nIntervalltyp / Umleitung'] != \"Umleitung\"]\n",
    "\n",
    "# filter constructions without bp_from or without bp_to\n",
    "construction_df = construction_df[construction_df['bp_from'].notnull()]\n",
    "construction_df = construction_df[construction_df['bp_to'].notnull()]\n",
    "\n",
    "connection_congestions = {}\n",
    "\n",
    "# passenger congestion: capacity reduction during day \n",
    "for index, row in construction_df.iterrows():\n",
    "    umsetzung = row['Umsetzung / \\nIntervalltyp / Umleitung']\n",
    "    if umsetzung not in ['Umsetzung', 'Sperre Strecke 24 Std', 'Sperre Strecke Tag']:\n",
    "        continue # not during day\n",
    "    from_op = row['bp_from']\n",
    "    to_op = row['bp_to']\n",
    "    \n",
    "    if from_op not in points.keys() or to_op not in points.keys(): # location not known\n",
    "        continue\n",
    "    if from_op == to_op: # op congestion\n",
    "        continue\n",
    "    else: # connection congestion\n",
    "        reduction_frac = row['reduction of capacity']\n",
    "        if math.isnan(reduction_frac):\n",
    "            reduction_frac = 0\n",
    "        \n",
    "        # BFS starting at from_op        \n",
    "        frontier = [from_op]\n",
    "        visited = set()\n",
    "        visited.add(from_op)\n",
    "        prev = {}\n",
    "        while len(frontier) > 0:\n",
    "            element = frontier.pop(0)\n",
    "            if element == to_op:\n",
    "                break\n",
    "            for incident_connection in points[element].connections_outbound:\n",
    "                neighbor = incident_connection.to_op\n",
    "                if neighbor not in visited:\n",
    "                    frontier.append(neighbor)\n",
    "                    prev[neighbor] = element\n",
    "                    visited.add(neighbor)\n",
    "            for incident_connection in points[element].connections_inbound:\n",
    "                neighbor = incident_connection.from_op\n",
    "                if neighbor not in visited and neighbor in points.keys():\n",
    "                    frontier.append(neighbor)\n",
    "                    prev[neighbor] = element\n",
    "                    visited.add(neighbor)\n",
    "         \n",
    "        # backtracking\n",
    "        assert(element == to_op) # check that a route was found\n",
    "        route = [to_op]\n",
    "        current = to_op\n",
    "        while current in prev.keys():\n",
    "            current = prev[current]\n",
    "            route.append(current)\n",
    "        \n",
    "        # count total trains\n",
    "        total_trains = 0\n",
    "        for from_op in route:\n",
    "            for outbound_connection in points[from_op].connections_outbound:\n",
    "                to_op = outbound_connection.to_op\n",
    "                if to_op in route and outbound_connection.train_type == 'PERSONENVERKEHR':\n",
    "                    trains = outbound_connection.trains\n",
    "                    smaller_op = from_op if from_op <= to_op else to_op\n",
    "                    greater_op = to_op if from_op <= to_op else from_op\n",
    "                    connection_congestions.setdefault((smaller_op, greater_op), Connection_congestion(smaller_op, greater_op))\n",
    "                    connection_congestions[(smaller_op, greater_op)].congestion.increase_passenger_value(reduction_frac * trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for connection_congestion in connection_congestions.values():\n",
    "    print(connection_congestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(connection_congestions.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polyhack",
   "language": "python",
   "name": "polyhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
